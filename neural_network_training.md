# A Paper List for Neural Network Training

This is a paper list for neural network training.

## Paper List

- Nitish Srivastava et al. Dropout:  A Simple Way to Prevent Neural Networks from Overfitting. JMLR 2014. [[paper]][1]

- Sergey Ioffe, Christian Szegedy. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. ICML 2015. [[paper]][2]

- Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton. Layer Normalization. arXiv preprint 2016. [[paper]][3]

- Wojciech Zaremba et al. Recurrent Neural Network Regularization. arXiv preprint 2014. [[paper]][4]

- Shuai Li et al. Independently Recurrent Neural Network (IndRNN): Building A Longer and Deeper RNN. CVPR 2018. [[paper]][5]

- Jie Hu et al. Squeeze-and-Excitation Networks. CVPR 2018. [[paper]][6]

[1]: http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer
[2]: https://arxiv.org/abs/1502.03167
[3]: https://arxiv.org/abs/1607.06450
[4]: https://arxiv.org/abs/1409.2329
[5]: https://arxiv.org/abs/1803.04831
[6]: https://arxiv.org/abs/1709.01507